''' Runs experiments exploring the effect of extinction events on the
complexity of maps generated by a trained RL agent.'''
import math
import os
import re
import shutil
import time

import gym
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import torch
from cycler import cycler
from PIL import Image
from scipy.stats import mannwhitneyu

import game_of_life
import gym_city
from arguments import get_parser
from envs import VecPyTorch, make_vec_envs
from evaluate import Evaluator
from model import Policy
from utils import get_vec_normalize

#plt.switch_backend('agg')
default_cycler = (cycler(color=[
    '#2aa24a',
    '#22a0f5',
    '#e24cae',
    '#f1b713']))

#plt.rc('lines', linewidth=4)
plt.rc('axes', prop_cycle=default_cycler)

def parse_cl_args():
    #TODO: away with this function, in theory.
    '''
    Takes arguments from the command line and ignores as many of them as possible.
    '''

    # assume the user passes no args, and these are defaults/dummy
    #TODO: trash all of this
    parser = get_parser()

    parser.add_argument('--non-det', action='store_true', default=False,
                        help='whether to use a non-deterministic policy')
    parser.add_argument('--active-column', default=None, type=int,
                        help='Run only one vertical column of a fractal model to see what it\
                        has learnt independently')
    parser.add_argument('--evaluate', action='store_true', default=False,
                        help='record trained network\'s performance')
    # add any experiment-specific args here
    args = parser.parse_args()
    args.im_render = True
   #args.render = True
    args.random_terrain = True
    args.random_builds = True

    return args



class ExtinctionEvaluator():
    '''Run a series of experiments to evaluate the effect of extinction events on the complexity
    of the behaviour of a trained agent.'''
    def __init__(self, args, im_log_dir):
        self.im_log_dir = im_log_dir
        self.log_dir = args.load_dir
        env_name = args.env_name

        if torch.cuda.is_available() and not args.no_cuda:
            args.cuda = True
            device = torch.device('cuda')
            map_location = torch.device('cuda')
        else:
            args.cuda = False
            device = torch.device('cpu')
            map_location = torch.device('cpu')
        self.device = device
        try:
            checkpoint = torch.load(os.path.join(args.load_dir, env_name + '.tar'),
                                    map_location=map_location)
        except FileNotFoundError:
            print('load-dir does not start with valid gym environment id, using command line args')
            env_name = args.env_name
            checkpoint = torch.load(os.path.join(args.load_dir, env_name + '.tar'),
                                map_location=map_location)
        saved_args = checkpoint['args']
        past_frames = checkpoint['n_frames']
        args.past_frames = past_frames
        env_name = saved_args.env_name

        if 'Micropolis' in env_name:
            args.power_puzzle = saved_args.power_puzzle

        if not args.evaluate and not 'GoLMulti' in env_name:
            # assume we just want to observe/interact w/ a single env.
           #args.num_proc = 1
            pass
        dummy_args = args
        dummy_args.poet = True
        print('extinction evaluator random map? {}'.format(args.random_terrain))
        envs = make_vec_envs(env_name, args.seed, args.num_processes, args.gamma,
                            args.load_dir, args.add_timestep, device=device,
                            allow_early_resets=False,
                            args=dummy_args)
        print('args.load_dir: {}'.format(args.load_dir))

        if isinstance(envs.observation_space, gym.spaces.Discrete):
            in_width = 1
            num_inputs = envs.observation_space.n
        elif isinstance(envs.observation_space, gym.spaces.Box):
           #if len(envs.observation_space.shape) == 3:
            in_w = envs.observation_space.shape[-2]
            in_h = envs.observation_space.shape[-1]
           #else:
           #    in_w = 1
           #    in_h = 1
            num_inputs = envs.observation_space.shape[0]

        if isinstance(envs.action_space, gym.spaces.Discrete):
            out_w = 1
            out_h = 1
            num_actions = int(envs.action_space.n // (in_w * in_h))
           #if 'Micropolis' in env_name:
           #    num_actions = env.venv.venv.envs[0].num_tools
           #elif 'GameOfLife' in env_name:
           #    num_actions = 1
           #else:
           #    num_actions = env.action_space.n
        elif isinstance(envs.action_space, gym.spaces.Box):
            out_w = envs.action_space.shape[0]
            out_h = envs.action_space.shape[1]
            num_actions = envs.action_space.shape[-1]
      # print('num_actions: {}'.format(num_actions))
        # We need to use the same statistics for normalization as used in training
        #actor_critic, ob_rms = \
        #            torch.load(os.path.join(args.load_dir, args.env_name + ".pt"))

        if saved_args.model == 'fractal':
            saved_args.model = 'FractalNet'
        actor_critic = Policy(envs.observation_space.shape, envs.action_space,
                base_kwargs={'map_width': args.map_width,
                             'recurrent': args.recurrent_policy,
                            'in_w': in_w, 'in_h': in_h, 'num_inputs': num_inputs,
                            'out_w': out_w, 'out_h': out_h , 'num_actions': num_actions},
                             curiosity=args.curiosity, algo=saved_args.algo,
                             model=saved_args.model, args=saved_args)
        actor_critic.to(device)
        torch.nn.Module.dump_patches = True
        actor_critic.load_state_dict(checkpoint['model_state_dict'])
        ob_rms = checkpoint['ob_rms']

        if 'fractal' in args.model.lower():
            new_recs = args.n_recs - saved_args.n_recs

            for nr in range(new_recs):
                actor_critic.base.auto_expand()
            print('expanded network:\n', actor_critic.base)

            if args.active_column is not None \
                    and hasattr(actor_critic.base, 'set_active_column'):
                actor_critic.base.set_active_column(args.active_column)
        vec_norm = get_vec_normalize(envs)

        if vec_norm is not None:
            vec_norm.eval()
            vec_norm.ob_rms = ob_rms
        self.actor_critic = actor_critic
        self.envs = envs
        self.args = args

    def run_experiment(self, n_epis, max_step, map_width, extinction_type, extinction_prob,
            extinction_dels):
        '''Evaluate the effect of a single type of extinction event (or none).'''
        args = self.args
        actor_critic = self.actor_critic
        envs = self.envs
        im_log_dir = '{}/width:{}_xttyp:{}_xtprob:{}_stp:{}'.format(
                self.im_log_dir,
                map_width,
                extinction_type,
                extinction_prob,
                max_step
                )
        envs.set_log_dir(im_log_dir)
        # adjust envs in general
        envs.configure(map_width=map_width, max_step=max_step, render=args.render, num_proc=args.num_processes,
                                  poet=args.poet, cuda=not args.no_cuda, random_terrain=args.random_terrain,
                                  random_builds=args.random_builds)
        print('obs space: {}'.format(envs.observation_space))
        envs.observation_space, _ = envs.get_spaces()

        if extinction_type is not None:
            # adjust extinguisher wrapper
            envs.set_extinction_type(extinction_type, extinction_prob, extinction_dels)
        # adjust image render wrapper
        envs.reset_episodes(im_log_dir)
        recurrent_hidden_states = torch.zeros(1, actor_critic.recurrent_hidden_state_size)
        masks = torch.zeros(1, 1)
        envs.init_storage()
        obs = envs.reset().to(self.device)
        #obs = torch.Tensor(obs)
        player_act = None
        n_episode = 0
        exp_infos = {}
        # all envs must be on same step relative to start of episode in this implementation
        n_step = 0
        last_rew = None

        while n_episode < n_epis:
            with torch.no_grad():
                value, action, _, recurrent_hidden_states = actor_critic.act(
                    obs, recurrent_hidden_states, masks, deterministic=not args.non_det,
                    player_act=player_act)
            # Observe reward and next obs
            obs, reward, done, infos = envs.step(action)
            obs = obs.to(self.device)

            if exp_infos == {}:
                for k, v in infos[0].items():
                    exp_infos[k] = np.zeros(shape=(max_step + 1, n_epis))
                exp_infos['reward'] = np.zeros(shape=(max_step + 1, n_epis))
            else:
                for k, v in infos[0].items():
                    if k in exp_infos:
                        if isinstance(v, torch.Tensor):
                            v = v.cpu()
                        exp_infos[k][n_step][n_episode: n_episode + self.args.num_processes] = v
                    else:
                        pass

                if last_rew is not None:
                    cum_rew = reward + last_rew
                else:
                    cum_rew = reward
                last_rew = cum_rew
               #print(cum_rew)
               #exp_infos['step'][n_step][n_episode: n_episode + n_epis] = n_step
                exp_infos['reward'][n_step][n_episode: n_episode + self.args.num_processes] = cum_rew.squeeze(-1)

            if args.render:
                envs.render()

            if done.all():
                n_step = 0

                if isinstance(done, torch.Tensor):
                    n_episode += torch.sum(done)
                elif isinstance(done, np.ndarray):
                    n_episode += np.sum(done)
                last_rew = None
            else:
                n_step += 1
            player_act = None

            if infos[0]:
                if 'player_move' in infos[0].keys():
                    player_act = infos[0]['player_move']
           #masks.fill_(0.0 if done else 1.0)

        final_infos = {}
        # take average over episodes at each timestep

        for k in exp_infos:
            final_infos[k] = exp_infos[k][-1, :]

        for k, v in exp_infos.items():
            # the saved dictionary stores the mean over episodes at each timestep
            exp_infos[k] = np.mean(v, axis=1), np.std(v, axis=1)
        np_save_dir = '{}/exp_infos'.format(im_log_dir)
        np.save(np_save_dir, exp_infos)
        envs.reset()

        return final_infos

#def run_experiment():
#    '''Measure True under various conditions.'''
#    map_sizes = self.map_sizes
#    extinction_types = self.extinction_types
#    extinction_intervals = self.extinction_intervals
#    evaluator = ExtinctionEvaluator()
#
#    for map_size in map_sizes:
#        for extinction_type in extinction_types:
#            for extinction_interval in extinction_intervals:
#                evaluator.run_experiment(map_size, extinction_type, extinction_interval)

def get_xy_cmprs(exp_dir):
    '''Plot the mean episode by mean size of the functional jpeg in terms of timestep.
    - exp_dir: location of images
    Return xy coordinates of mean episode
    '''
    ims = os.listdir(exp_dir)
    # map timesteps to a tuple (mean_size, num_ims)
    step2size = {}

    for im in ims:
        step_search = re.search(r'([\d]+)\.jpg', im)

        if not step_search:
            continue
        step = step_search.group(1)
        print(step)
        im_path = os.path.join(exp_dir, im)
        size = os.stat(im_path).st_size

        if step in step2size:
            mean_size, num_ims = step2size[step]
            mean_size = (mean_size * num_ims + size) / (num_ims + 1)
            num_ims += 1
            step2size[step] = (mean_size, num_ims)
        else:
            step2size[step] = (size, 1)
    xs = []
    ys = []

    for x, (y, _) in step2size.items():
        xs += [x]
        ys += [y]
    xy = zip(xs, ys)
    xy = sorted(xy, key = lambda x: int(x[0]))
    xs, ys = zip(*xy)

    return xs, ys





def get_xy_metric(exp_dir, metric):
    info_dir = os.path.join('{}'.format(exp_dir), 'exp_infos.npy')
    exp_infos = np.load(info_dir, allow_pickle=True).item()
   #print(exp_infos[metric][0].shape)
#   if metric == 'reward':
#      #print(type(exp_infos[metric][0]))
#       stdevs = exp_infos[metric][1]
#       stdevs = np.zeros(exp_infos[metric][1].shape)
#       exp_infos[metric] = (exp_infos[metric][0] - exp_infos[metric][0][0], stdevs)
   #    j = 0
   #    # actually mean reward over trials/episodes!!
   #    rewards = np.copy(exp_infos['reward'][0])
   #    total_reward = np.sum(rewards)/ len(rewards)
   #    rewards = rewards - total_reward
   #    i = 0
   #    last_r = 0
   #    for r in rewards:
   #        exp_infos['reward'][j][i] = r
   #       #exp_infos['reward'][j][i] = np.sum(rewards[:i + 1])
   #        i += 1
   #    print(exp_infos['reward'][0])
   #    print(len(exp_infos['reward'][0]))
   #    j += 1
   #    print('{} episodes'.format(j))
   #xy = enumerate(exp_infos[metric][0])
    #FIXME: Hackish, to fix drastic jumps after first steps that are probably symptoms of problems with logging during
    # experimentation
    xy = enumerate(exp_infos[metric][0][:])
    x_std = enumerate(exp_infos[metric][1][:])
    xy = sorted(xy, key = lambda x: int(x[0]))
    x_std = sorted(x_std, key = lambda x: int(x[0]))
    xs, ys = zip(*xy)
    _, stds = zip(*x_std)

    return xs, ys, stds

class ExtinctionExperimenter():
    '''
    Coordinate between experimentation and visualization.
    '''
    def __init__(self, log_dir):
        args = parse_cl_args()
        env_name = log_dir.split('/')[-1].split('_')[0]
        args.env_name = env_name
        # Experiment global parameters
       #self.max_step = [1000]
        self.max_step = [args.max_step]
        #
        self.xt_types = [
                'random',
                'spatial',
                'age',
                'None',
                ]
        # TODO: automate xt_probs

        if 'golmulti' in env_name.lower():
            self.n_epis = 40
            self.xt_dels = [25]
        elif 'micropolis' in env_name.lower():
            self.n_epis = 21
            self.xt_dels = [15]
       #self.map_sizes = [args.map_width]
        self.map_sizes = [
                16,
                32,
                64,
                ]
        self.xt_probs = [
               #0.005,
                0.01,
                0.02,
                0.04,
                ]
        exp_name = 'test_col:{}_xtdels:{}'.format(
                args.active_column,
                self.xt_dels[0])
        self.log_dir = log_dir
        args.load_dir = log_dir
        im_log_dir = os.path.join(log_dir, exp_name)
        try:
            os.mkdir(im_log_dir)
        except FileExistsError:
           #shutil.rmtree(im_log_dir)
           #os.mkdir(im_log_dir)
            pass
        self.im_log_dir = im_log_dir
        self.evaluator = ExtinctionEvaluator(args, im_log_dir)

    def visualize_metric(self, n_row_outer, n_col_outer, log_dir, metric='compressibility'):
        '''Visualize results from extinction-compressibility experiments.
         - load-dir: stores folder of experiments, within which are compressed images named by rank and
           episode
        '''
        xtinct_dirs = os.listdir(log_dir)
        xt_dir_paths = [os.path.join(log_dir, xt_dir) for xt_dir in xtinct_dirs]
        # make sure the order of local and global paths correspond
        dirs_types = zip(xtinct_dirs, xt_dir_paths)
        dirs_types = sorted(dirs_types, key = lambda x: str(x[0]))
        xtinct_dirs, xt_dir_paths = zip(*dirs_types)
        xt_ims = [os.listdir(xt_dir) for xt_dir in xt_dir_paths if not os.path.isfile(xt_dir) ]

        metrics2labels = {
                # Game of Life
                'pop': ('Living Cells', 'population'),
                # Micropolis
                'ind_pop': ('industrial', 'population'),
                'res_pop': ('residential', 'population'),
                'com_pop': ('commercial', 'population'),
                'num_plants': ('power plants', 'population'),
                'traffic': ('traffic', 'population'),
                'mayor_rating': ('mayor rating', '% approval'),
                'reward': ('fitness', 'reward'),
                'jpeg_size': ('inverse compressibility', 'bytes per jpeg'),
                }
        j = 0
        n_row = 0
        xmin, xmax, ymin, ymax = 0, 0, 0, 0

        all_p_vals = np.load(os.path.join(self.im_log_dir, 'pvals.npy'), allow_pickle=True).item()
        inner_grid1 = self.inner_grid1
       #inner_grid2 = self.inner_grid2
        n_xtt = len(self.xt_types)
        rows = self.xt_types[:-1]
        cols = self.xt_types[1:]

        for map_size in self.map_sizes:
            n_col = 0
            inner_axes1 = []
           #inner_axes2 = []
           #print(all_p_vals)
            for xt_prob in self.xt_probs:
                table_data = np.empty((n_xtt - 1, n_xtt - 1)).tolist()
                table_fill = np.empty((n_xtt - 1, n_xtt - 1), dtype=object)
                table_fill.fill((0,0,0,0))
                table_fill = table_fill.tolist()
                plt.figure(2)
                xt_i = 0

                for xtt1_i in range(len(self.xt_types) - 1):
                    xtt1 = rows[xtt1_i]
                    xt_j = 0

                    for xtt2_i in range(len(self.xt_types) - 1):
                        xtt2 = cols[xtt2_i]

                        if xt_j < xt_i:
                            table_data[xt_i][xt_j] = ''
                        elif xtt1 != xtt2:
                            p_vals = all_p_vals['{}_{}'.format(map_size, xt_prob)]['{}_{}_{}'.format(metric, xtt1, xtt2)]

                            if p_vals is None:
                                table_data[xt_i][xt_j] = 1
                            else:
                                if p_vals == 1:
                                    p_vals = (0, p_vals)

                                if p_vals[1] is not None and p_vals[1] < 0.05:
                                    # green highlight
                                    table_fill[xt_i][xt_j] = (0, 1, 0, 0.3)
                                table_data[xt_i][xt_j] = '{0:0.0e}'.format(p_vals[1])
                        else:
                            table_data[xt_i][xt_j] = '1'
                        xt_j += 1
                    xt_i += 1
               #ax2= self.fig2.add_subplot(inner_grid2[j])
               #if n_col != 0:
               #    rows = None
               #else:
               #    rows = self.xt_types
                plt.subplots_adjust(left=0.2, bottom=0.2)
               #ax2.get_xaxis().set_visible(False)
               #ax2.get_yaxis().set_visible(False)
               #self.fig2.add_subplot(ax2)
               #inner_axes2.append(ax2)
                plt.figure(1)
                ax1= self.fig1.add_subplot(inner_grid1[j])
                inner_axes1.append(ax1)
                y_label = ''

                if n_col == 0 and n_col_outer == 0:
                    y_label += 'map size = {}\n\n'.format(map_size)
                plt_title = ''
                metric_title, metric_y_label = metrics2labels[metric]

                if n_row == 1:
                    y_label += '{}'.format(metric_y_label)
                plt.ylabel(y_label)
                plt.figure(1)
                plt_title = ''
               #ax2.patch.set_alpha(0.4)
                x_label = ''

                if n_col == 1 and n_row == 0:
                    plt_title += '{}'.format(metric_title)

                if n_row == 0:
                    x_label +='extinction frequency = {}'.format(xt_prob)
                    plt.figure(1)
                    plt.xlabel(x_label)
                    plt.xlabel(x_label)
                    ax1.xaxis.set_label_position('top')
                   #ax2.xaxis.set_label_position('top')
               #ax.xaxis.tick_top()
                plt.figure(1)
                plt.title(plt_title)
                plt.title(plt_title)
                plt.figure(1)

                if n_row == 2 and n_col == 1:
                    plt.xlabel('timesteps')

                for i, trial_name in enumerate(xtinct_dirs):
                    srch_xttyp = re.search(r'xttyp\:([a-zA-Z]+)', trial_name)

                    if srch_xttyp is None:
                        continue
                    xt_type = srch_xttyp.group(1)
                    xt_dir = xt_dir_paths[i]

                    if xt_type != 'None':
                        srch_xtprob = re.search(r'xtprob\:({})'.format(xt_prob), trial_name)

                        if srch_xtprob is None:
                            continue
                        xt_interval = int(1 / float(xt_prob))
                    srch_width = re.search(r'width\:({})'.format(map_size), trial_name)

                    if srch_width is None:
                        continue

                    srch_stp = re.search(r'stp\:({})'.format(self.evaluator.args.max_step), trial_name)

                    if srch_stp is None:
                        continue

                    exp_title = ' '.join(xt_dir.split('/')[-2:])

                    if os.path.isfile(xt_dir):
                        continue
                   #if metric == 'compressibility':
                   #    x, y = get_xy_cmprs(xt_dir)
                   #    e = None
                   #else:
                    x, y, e = get_xy_metric(xt_dir, metric)
                      # y, e = y *

                    markers, caps, bars = ax1.errorbar(x, y, e, alpha=1)
                    [bar.set_alpha(0.03) for bar in bars]
                    markers.set_label(xt_type)
                    xmin_i, xmax_i = ax1.get_xlim()
                    ymin_i, ymax_i = ax1.get_ylim()

                    if xmin_i < xmin:
                        xmin = xmin_i

                    if xmax_i > xmax:
                        xmax = xmax_i

                    if ymin_i < ymin and ymin_i != 0:
                        ymin=ymin_i

                    if ymax_i > ymax:
                        ymax = ymax_i

               #print('metric {}, size {}, prob {}'.format(metric, map_size, xt_prob))
               #print('ymin {} ymax {}'.format(ymin, ymax))
                if n_col != 0:
                    ax1.set_yticks([])
                    plt.ylabel('')

                if n_row != 2:
                    ax1.set_xticks([])

                if n_row != 0:
                    plt.title('')
                self.fig1.add_subplot(ax1)
               #ax2.set_yticks([])
               #ax2.set_xticks([])
                if n_col == 1 and n_row == 1:
                    ax1.legend(fancybox=True, framealpha=0.5)
                j += 1

                if n_row == 2:
                    bottom = -0.7
                else:
                    bottom = -0.4
                table  = ax1.table(table_data, rowLabels=rows, colLabels=cols, loc='bottom',
                        bbox=[0.2, bottom, 0.75, 0.4], cellColours=table_fill, rowLoc='right',
                        colWidths=[.25,.25,.25])
                n_col += 1
            n_row += 1
            k = 0

            for ax1 in inner_axes1:
                if metric in self.param_trgs:
                    trg = self.param_trgs[metric]
                    trg_height = min(trg, (ymax - ymin) * 0.97 + ymin)
                    txt_height = trg_height - 0.1 * (ymax- ymin)
                    e_xmin, e_xmax = xmin + (xmax - xmin) * 0.05, xmax - (xmax - xmin) * 0.05
                    ax1.hlines(trg_height, e_xmin, e_xmax, linestyles='dashed', colors='grey', label='target')

                    if k == len(inner_axes1) - 2 and n_row == 2:
                        ax1.annotate('target = {}'.format(int(trg)), (e_xmin, txt_height))

                if metric == 'jpeg_size':# and map_size == 64:
                    ymin = 600

                ax1.set_xlim([xmin, xmax])
                ax1.set_ylim([ymin, ymax])
                k += 1






      ##graph_title = 'extinction interval = {}'.format(xt_interval)
      ##plt.title(graph_title)
      # plt.xlabel('timesteps')
      # if metric == 'compressibility':
      #     print('DOIIINN')
      #     plt.ylabel('bytes per jpeg')
      # else:
      #     plt.ylabel(metric)
      ##plt.xticks([25 * i for i in range(5)])
      # plt.legend()

    def run_experiments(self):
        '''Run experiments and produce data.'''
        evaluator = self.evaluator

        all_final_infos = {}

        for mst in self.max_step:
            for msz in self.map_sizes:
                for xtd in self.xt_dels:
                    xtt_infos = {}

                    for xtt in self.xt_types:
                        if xtt == 'None':
                            xtps = [0]
                        else:
                            xtps = self.xt_probs

                        for xtp in xtps:
                            final_infos = evaluator.run_experiment(self.n_epis, mst, msz, xtt, xtp, xtd)
                           #run_id = 's{}_w{}_xtd{}_xtp{}'.format(mst, msz, xtd, xtp)
                            # FIXME: only works for this particular paper!
                            # copy paste the results for None-type extinction to entries for all probabilities
                            # FIXME: avoid this copy-pasting

                            if xtt == 'None':
                                run_ids = ['{}_{}'.format(msz, xtp_dum) for xtp_dum in self.xt_probs]
                            else:
                                run_ids = ['{}_{}'.format(msz, xtp)]

                            for run_id in run_ids:
                                if run_id not in all_final_infos:
                                    all_final_infos[run_id] = {xtt: final_infos}
                                else:
                                    all_final_infos[run_id][xtt] = final_infos
        run_pvals = {}
        self.metrics = {}
        save_path = os.path.join(self.im_log_dir, 'final_infos.npy')
        np.save(save_path, all_final_infos)

        for run in all_final_infos:
            p_vals = {}
            # compare every pair of extinction types

            for t1 in all_final_infos[run]:
                for t2 in all_final_infos[run]:
                    if t1 == t2:
                        continue
                    # w.r.t. each metric

                    for m in all_final_infos[run][t1]:
                        pval_name = '{}_{}_{}'.format(m, t1, t2)
                        x = all_final_infos[run][t1][m]
                        y = all_final_infos[run][t2][m]
                        try:
                            p_vals[pval_name] = mannwhitneyu(x, y)
                        except ValueError as verr:
                            p_vals[pval_name] = 1
                        self.metrics[m] = None
            run_pvals[run] = p_vals
        save_path = os.path.join(self.im_log_dir, 'pvals.npy')
        np.save(save_path, run_pvals)


    def visualize_experiments(self):
        '''
        Visualize compressibility data stored in subfolders of the current directory.
        '''
        META_GRAPH = False
        param_bounds = self.evaluator.envs.get_param_bounds()
        self.param_trgs = self.evaluator.envs.get_param_trgs()
        print('param trgs {}'.format(self.param_trgs))
        params = list(self.param_trgs.keys())
        params.append('jpeg_size')
        params.append('reward')
        n_params = len(params)

        if META_GRAPH:
            if 'micropolis' in self.evaluator.args.env_name.lower():
                n_cols = 2

            if 'golmulti' in self.evaluator.args.env_name.lower():
                n_cols = 1
            n_rows = math.ceil(n_params / n_cols)
            fig1 = plt.figure(1, figsize=(n_cols * 9, n_rows * 8), constrained_layout=False)
        else:
            n_cols = 1
            n_rows = 1
            fig1 = plt.figure(1, figsize=(n_cols * 9, n_rows * 8), constrained_layout=False)
        plt.figure(1)
        self.fig1 = fig1
        i = 0
        outer_grid1 = fig1.add_gridspec(n_rows, n_cols, wspace = 0.1, hspace=0.3)
        n_row = 0
        n_col = 0
        envs2titles = {'MicropolisEnv-v0': 'SimCity',
                       'GoLMultiEnv-v0': 'Game of Life'}
        title = envs2titles[self.evaluator.args.env_name]

        for param in params:
            n_row = i // n_cols
            n_col = i % n_cols
            self.inner_grid1 = outer_grid1[i].subgridspec(3, 3, wspace=0.0, hspace=0.4)
            self.visualize_metric(n_row, n_col, self.im_log_dir, metric=param)

            if not META_GRAPH:
                plt.suptitle(title)
                plt.tight_layout()
                fig1.subplots_adjust(top=0.91, bottom=0.15)
                plt.savefig(os.path.join(self.log_dir, '{} {}.png'.format(title, param)), format='png')
                plt.clf()

            if META_GRAPH:
                i += 1

       #graph_title = 'map_size = {}, extinct_int = {}'.format(self.map_sizes[0], self.xt_probs[0])
        graph_title1 = 'size_X_xtprob'
        graph_title2 = 'xtt_X_xtt_pvals'

        fig1.suptitle(title)
        fig1.tight_layout()
        fig1.subplots_adjust(top=0.96, bottom=0.05)
        plt.figure(1)
        plt.savefig(os.path.join(self.log_dir, '{}.png'.format(graph_title1)), format='png')
       #plt.savefig(os.path.join(self.log_dir, '{}.png'.format(graph_title2)), format='png')

if __name__ == "__main__":
    VIS_ONLY = False
   #VIS_ONLY = True
    LOG_DIR = os.path.abspath(os.path.join(
        'trained_models',
        'a2c_FractalNet_drop',
       #'a2c_FractalNet',
       #'MicropolisEnv-v0_w16_300s_noExtinction.test',
       #'GoLMultiEnv-v0_w16_200s_teachPop_noTick_noExtinct',
        'MicropolisEnv-v0_w16_300s_noExtinction',
       #'GoLMultiEnv-v0_w16_200s_teachPop_GoL_noExtinct',
       #'MicropolisEnv-v0_w16_200s_noXt2_alpgmm_DUMMY_2.test',
       #'MicropolisEnv-v0_w16_200s_noXt2_alpgmm.test',
       #'GoLMultiEnv-v0_w16_200s_jinkyFix',
        ))
    EXPERIMENTER = ExtinctionExperimenter(LOG_DIR)

    #TODO: hacky; detect incomplete folders automatically,
    #     should save numpy object w/ stats in folder

    if not VIS_ONLY:
        EXPERIMENTER.run_experiments()
       #try:
       ## broadcast problem when sizing up map #TODO: adjust vec_envs to prevent this
       #except ValueError as ve:
    EXPERIMENTER.visualize_experiments()
   #EXPERIMENTER.visualize_p_vals()
